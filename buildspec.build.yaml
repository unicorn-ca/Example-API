#
# Sample Buildspec file
#
# Deployment is done within ubuntu 18.04 docker image (i.e. aws/codebuild/standard:2.0 --> ubuntu/standard/2.0)
# This should be a root user by default
#
# Please ensure that the buildspec does not conatin anything that waits on user input. E.g. use the -y flag
# to ensure apt does not ask for confirmation
#
# More info here: https://docs.aws.amazon.com/codebuild/latest/userguide/build-spec-ref.html
#

# Please forgive all the sample- The base pipeline has those hardcoded. I'll fix those soon
version: 0.2

phases:
    install:
        runtime-versions:
            nodejs: 10
            python: 3.7
    pre_build:
        commands:
            - curl -L https://github.com/mikefarah/yq/releases/download/2.4.0/yq_linux_amd64 -o /bin/yq
            - chmod +x /bin/yq
            - npm install -g serverless
            - npm install serverless-python-requirements
            - npm install serverless-ssm-fetch
            - npm install serverless-deployment-bucket --save-dev
    build:
        commands:
            # We override servlerless's default functionality by pointing its deployment at a custom bucket embedded in
            # the pipeline.
            #  First we check that there isn't a deploymentBucket specified, if there is we error
            #    otherwise we point it at the SAM bucket
            #
            #  Finding a better way of generically handling this (so its equally easy to deploy with serverless
            #   vs SAM vs Raw Cloudformation) is a priority for the next iteration
            #
            - |
              if [ `yq r serverless.yml provider.deploymentBucket.name` = 'null' ]; then
                  echo "No deployment bucket found - using $SAM_BUCKET";
                  yq w --inplace serverless.yml provider.deploymentBucket.name $SAM_BUCKET;
              else
                  echo 'Currently custom deployment buckets cannot be used';
                  exit 1;
              fi
              aws get-parameter --name "/variables/lambda/identifier" >> test.json
              IDENTIFIER=`jq -r .Parameter.LastModifiedDate` test.json && rm test.json
              now=$(date +%s)
              end=$(echo $IDENTIFIER | grep -Eo "[0-9]+\.[0-9]{0}" | cut -d"." -f1)
              diff=$(printf '%d\n' "$(( (now-end)/86400 ))")
            - | # If it has been less than 5 days, don't rotate the credentials otherwise new db is spun up.
              if [ $diff gt 5 ]; then
                  # Generating new random credentials
                  PASSWORD="$(python -c 'import uuid; print(uuid.uuid4().hex)')"
                  USERNAME="$(python -c 'import uuid, string, random; a=random.choice(string.ascii_letters)+uuid.uuid4().hex; print(a[0:15])')"
                  IDENTIFIER="$(python -c 'import uuid, string, random; a=random.choice(string.ascii_letters)+uuid.uuid4().hex; print(a[0:10])')"

                  aws ssm put-parameter --name "/variables/lambda/username" --value "$USERNAME" --type "SecureString" --overwrite
                  aws ssm put-parameter --name "/variables/lambda/password" --value "$PASSWORD" --type "SecureString" --overwrite
                  aws ssm put-parameter --name "/variables/lambda/identifier" --value "$IDENTIFIER" --type "SecureString" --overwrite
              else
                  # Using the same credentials
                  aws ssm get-parameter --name "/variables/lambda/username" --with-decryption >> username.json
                  aws ssm get-parameter --name "/variables/lambda/identifier" --with-decryption >> identifier.json
                  aws ssm get-parameter --name "/variables/lambda/password" --with-decryption >> password.json
                  IDENTIFIER=`jq -r .Parameter.Value identifier.json` && rm identifier.json
                  PASSWORD=`jq -r .Parameter.Value password.json` && rm password.json
                  USERNAME=`jq -r .Parameter.Value username.json` && rm username.json
              fi
            - sls package
            - |
                UNI_LOCAL_ARTF=`jq -r .service.artifact .serverless/serverless-state.json`
                UNI_S3_ARTF_DR=`jq -r .package.artifactDirectoryName .serverless/serverless-state.json`
                UNI_S3_ARTF_NM=`jq -r .package.artifact .serverless/serverless-state.json`
                S3_BUCKET=s3://$SAM_BUCKET/$UNI_S3_ARTF_DR/$UNI_S3_ARTF_NM
                aws configure set cli_follow_urlparam false
                aws s3 cp $UNI_LOCAL_ARTF $S3_BUCKET
                aws ssm put-parameter --name "/variables/lambda/s3_bucket" --value "$S3_BUCKET" --type "SecureString" --overwrite

                echo "{\"Parameters\": { \"Password\": \"${PASSWORD}\", \"Username\": \"${USERNAME}\", \"Identifier\": \"${IDENTIFIER}\"}}" > rds-config.json
                cat rds-config.json

            - >-
              echo '{"Parameters": {}}' > empty-configuration.json

    post_build:
        commands:
            # These are required to be output for this iteration. I'll see if we can make these optional later.
            - cp empty-configuration.json sample-configuration-dev.json
            - cp empty-configuration.json sample-configuration-prod.json
            - mv rds-config.json sample-configuration-rds.json
            # I don't know the difference between update-stack vs create-stack.json.
            # update-stack seems more complete but idk how they're invoked. Not sure that sls package is
            # the best solution either.
            - mv .serverless/cloudformation-template-update-stack.json sample-transformed.yaml

artifacts:
    files:
        - sample-transformed.yaml
        - sample-configuration-dev.json
        - sample-configuration-prod.json
        - sample-configuration-rds.json
        - rds.yml
